---
title: "Lesson 2"
author: "Cong Wang & Renan Serenini"
date: "2022-08-25"
draft: false
excerpt: 
weight: 1
links:
- icon: github
  icon_pack: fab
  name: code
  url: https://github.com/CongWang141/statistics-with-r.git
---



<div id="author" class="section level3">
<h3>author</h3>
<p>Cong Wang &amp; Renan Serenini</p>
</div>
<div id="introduction-of-plot-in-r" class="section level2">
<h2>Introduction of plot in R</h2>
<p>In high school, we all studied the plot of the function <span class="math inline">\(y=x^2 - 5\)</span>, which is a upward fan shape. Using R we can plot this curve</p>
<pre class="r"><code>curve(x^2 - 5)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>We can include some options to make the plot better, also add horizontal and vertical lines to this plot</p>
<pre class="r"><code>curve(x^2, xlim = c(-5,5), col = &quot;red&quot;)
abline(h = 0)
abline(v = 0)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="chi-squared-distribution" class="section level2">
<h2>Chi-squared distribution</h2>
<p>Except this simple function, R can plot all the statistic distributions, here shows an example of plotting a Chi-squared distribution</p>
<pre class="r"><code>curve(dchisq(x, df = 10), xlim = c(0, 40), ylab = &quot;density&quot;, xlab = &quot;Personal income&quot;) </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="drawing-a-sample" class="section level2">
<h2>Drawing a sample</h2>
<p>Here I will show you how to draw a sample from a Chi-squared distribution</p>
<div id="example-of-a-chi-squared-distribution" class="section level3">
<h3>example of a Chi-squared distribution</h3>
<p><code>set.seed(1)</code> to make sure you will get the same result as I do.</p>
<pre class="r"><code>set.seed(1)
sample1 &lt;- rchisq(n = 1000000, df = 12)
y1 &lt;- sample1[1]
ybar &lt;- mean(sample1)</code></pre>
<p>If we repeat the process for a lot of times <strong>y1</strong> will have the same distribution with the population, the mean of <strong>y1</strong> is the mean of population (12), so <strong>y1</strong> is unbiased. The variance of <strong>y1</strong> is also the same with population, <span class="math inline">\(2*12=24\)</span>. <strong>ybar</strong> is unbaised with mean 12. The variance of <strong>ybar</strong> will be 2*12/99, simply from the formula <span class="math display">\[S^2=\frac{\sum(x_i-\bar{x})^2}{n-1}\]</span>
Bacause the variance of sample mean is smaller than the population mean, which means that the sample mean is a more efficient estimate for the population mean.</p>
</div>
<div id="properites-of-sample-mean" class="section level3">
<h3>Properites of sample mean</h3>
<p>To investigate the properties of sample mean, we can generate multiple samples from the same population</p>
<pre class="r"><code>pop &lt;- rnorm(10000, 10, 1) #Population from a normal distribution, mean=10 and sd=1</code></pre>
<p>Get a sample from the population and estimate the mean</p>
<pre class="r"><code>sample(x=pop, size=5) #Draw a sample from our population</code></pre>
<pre><code>## [1]  9.934007 11.116345  8.491058 10.907192  9.720582</code></pre>
<pre class="r"><code>mean(sample(x=pop, size=5)) #Mean of the sample</code></pre>
<pre><code>## [1] 10.2328</code></pre>
<p>Use function <code>replicate</code>, we can replicate the process multiple times. The argument <code>expr =</code> specify what we need to replicate, <code>n =</code> specify how many times we want to repeat</p>
<pre class="r"><code>est1 &lt;- replicate(expr = mean(sample(x = pop, size = 5)), n = 25000) #Get the mean 25000 times

est2 &lt;- replicate(expr = mean(sample(x = pop, size = 25)), n = 25000) #Get the mean 25000 times, but with a larger sample

fo &lt;- replicate(expr = sample(x = pop, size = 5)[1], n = 25000) #The first observation of the sample, y1</code></pre>
<p>Plot the density estimate for the distribution in different cases</p>
<pre class="r"><code># pot density estimate for the ditribution of y1, first element of each sample
plot(density(fo), 
     col = &quot;green&quot;, 
     lwd = 2,
     ylim = c(0, 2),
     xlab = &quot;estimates&quot;,
     main = &quot;Sampling Distributions of Unbiased Estimators&quot;)
# add density estimate for the distribution of the sample mean with n=5 to the plot
lines(density(est1), 
      col = &quot;steelblue&quot;, 
      lwd = 2, 
      bty = &quot;l&quot;) #Lines, instead of plot, plots over the already existing graph
# add density estimate for the distribution of the sample mean with n=25 to the plot
lines(density(est2), 
      col = &quot;red2&quot;, 
      lwd = 2)
# add a vertical line at the true parameter
abline(v = 10, lty = 2)
# add N(10,1) density to the plot
curve(dnorm(x, mean = 10), 
      lwd = 2,
      lty = 2,
      add = T)

# add a legend
legend(&quot;topleft&quot;,
       legend = c(&quot;N(10,1)&quot;,
                  expression(Y[1]),
                  expression(bar(Y) ~ n == 5),
                  expression(bar(Y) ~ n == 25)
       ), 
       lty = c(2, 1, 1, 1), 
       col = c(&quot;black&quot;,&quot;green&quot;, &quot;steelblue&quot;, &quot;red2&quot;),
       lwd = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>As we can see from the plot, the sampling distribution of <strong>y1</strong> tracks the density of <strong>N(10,1)</strong>. As the number of observations increases, the sampling distribution gets closer to the true parameter. In another word, the probability of obtaining estimates that are close to the true value increases when the sample size increased.</p>
</div>
</div>
<div id="random-sampling" class="section level2">
<h2>Random sampling</h2>
<p>By using <code>?sample</code> we can see the documentation about this fucntion. You can add argument <code>prob</code> to specify the probability of an element being sampled</p>
<p>In this section, I will show the outcomes for simulating sample mean when the i.i.d. assumption fails. First we need to sort the population, and then replicate the sampling process without i.i.d. assumption</p>
<pre class="r"><code>sort(pop) #Population sorted</code></pre>
<pre class="r"><code>est3 &lt;-  replicate(n = 25000, 
                   expr = mean(sample(x = sort(pop), 
                                      size = 25, 
                                      prob = c(rep(4, 2500), rep(1, 7500)))))
mean(est3)</code></pre>
<pre><code>## [1] 9.447732</code></pre>
<p>Comparing the sampling distribution of sample mean when i.i.d. holds and fails</p>
<pre class="r"><code>plot(density(est2), 
     col = &quot;steelblue&quot;,
     lwd = 2,
     xlim = c(8, 11),
     xlab = &quot;Estimates&quot;,
     main = &quot;When the i.i.d. Assumption Fails&quot;)

# sampling distribution of sample mean, i.i.d. fails, n=25
lines(density(est3),
      col = &quot;red2&quot;,
      lwd = 2)
 
# add a legend
legend(&quot;topleft&quot;,
       legend = c(expression(bar(Y)[n == 25]~&quot;, i.i.d. fails&quot;),
                  expression(bar(Y)[n == 25]~&quot;, i.i.d. holds&quot;)
       ), 
       lty = c(1, 1), 
       col = c(&quot;red2&quot;, &quot;steelblue&quot;),
       lwd = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>As we can see from the plot <strong>ybar</strong> is biased estimator if i.i.d. doesn’t not hold</p>
</div>
<div id="hypothesis-testing" class="section level2">
<h2>Hypothesis testing</h2>
<p>Here we will see how to visualize p-value which is a very important statistic term</p>
<pre class="r"><code># plot the standard normal density on the interval [-4,4]
curve(dnorm(x),
      xlim = c(-4, 4),
      main = &quot;Calculating a p-Value&quot;,
      yaxs = &quot;i&quot;,
      xlab = &quot;z&quot;,
      ylab = &quot;&quot;,
      lwd = 2,
      axes = &quot;F&quot;)

# add x-axis
axis(1, 
     at = c(-1.5, 0, 1.5), 
     padj = 0.75,
     labels = c(expression(-frac(bar(Y)^&quot;act&quot;~-~bar(mu)[Y,0], sigma[bar(Y)])),
                0,
                expression(frac(bar(Y)^&quot;act&quot;~-~bar(mu)[Y,0], sigma[bar(Y)]))))

# shade p-value/2 region in left tail
polygon(x = c(-6, seq(-6, -1.5, 0.01), -1.5),
        y = c(0, dnorm(seq(-6, -1.5, 0.01)),0), 
        col = &quot;steelblue&quot;)

# shade p-value/2 region in right tail
polygon(x = c(1.5, seq(1.5, 6, 0.01), 6),
        y = c(0, dnorm(seq(1.5, 6, 0.01)), 0), 
        col = &quot;steelblue&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="sample-var-sd-and-se" class="section level2">
<h2>Sample var, sd and se</h2>
<p>Usually the variance of population in unknown, so we need to estimate it, and also the s.d.</p>
<pre class="r"><code># vector of sample sizes
n &lt;- c(10000, 5000, 2000, 1000, 500)
# sample observations, estimate using &#39;sd()&#39; and plot the estimated distributions
sd(n)</code></pre>
<pre><code>## [1] 3930.649</code></pre>
<p>In this case, we draw a sample of 10000 obeservations from a normal distribution with mean equals to 10, standard deviation equals to 3, then we calulate the standard deviation of the sample, we repeat this process for <strong>n = 10000</strong> times, finally we plot the density of the sequence of the standard deviation we got</p>
<pre class="r"><code>sq_y &lt;- replicate(n = 10000, expr = sd(rnorm(n[1], mean = 10, sd = 3)))
plot(density(sq_y),
     main = expression(&quot;Sampling Distributions of&quot; ~ s[Y]),
     xlab = expression(s[y]),
     lwd = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Next, we create a loop to draw samples of 5000, 2000, 1000, 500 obeservations from a normal distribution with mean equals to 10, standard deviation equals to 3, just like what we have done before. For each sample we calulate the standard deviations, and we repeat each process for <strong>n = 10000</strong> times. Finally, we plot the density of each sequence of the standard deviation we got for comparison.</p>
<pre class="r"><code>plot(density(sq_y),
     main = expression(&quot;Sampling Distributions of&quot; ~ s[Y]),
     xlab = expression(s[y]),
     lwd = 2)

for (i in 2:5) {
  sq_y &lt;- replicate(n = 10000, expr = sd(rnorm(n[i], 10, 3)))
  lines(density(sq_y), 
        col = i, 
        lwd = 2)
  
  }
# add a legend
legend(&quot;topleft&quot;,
       legend = c(expression(n == 10000),
                  expression(n == 5000),
                  expression(n == 2000),
                  expression(n == 1000),
                  expression(n == 500)), 
       col = 1:5,
       lwd = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>From the plot, we can see that when the sample size is bigger, the estimate is closer to the true value.</p>
</div>
<div id="p-value-when-standard-deviation-is-unknown" class="section level2">
<h2>P-value when standard deviation is unknown</h2>
<p>First we draw a sample with replacement from a bernoulli distribution, with 90% probability of 0 and 10% probability of 1, sample size = 100. Then get the actual sample mean.</p>
<pre class="r"><code>random_sample &lt;- sample(0:1, 
         prob = c(0.9, 0.1), 
         replace = T, 
         size = 100) #sampling from a bernoulli distribution
samplemean_act &lt;- mean(random_sample) #Mean of the sample</code></pre>
<p>We know for a bernoulli distribution, the variance of the sample mean is
<span class="math display">\[var=pq\]</span>
So we can get the standard error of the sample mean from a bernoulli distribution <span class="math display">\[se=\frac{sd}{\sqrt[2]{n}}=\sqrt{\frac{pq}{n}}\]</span></p>
<pre class="r"><code>SE_samplemean &lt;- sqrt(samplemean_act * (1 - samplemean_act) / 100) #Standard error</code></pre>
</div>
<div id="null-hypothesis-testing" class="section level2">
<h2>Null hypothesis testing</h2>
<p>Compute t-statistic</p>
<pre class="r"><code>tstatistic &lt;- (samplemean_act - 0) / SE_samplemean
tstatistic</code></pre>
<pre><code>## [1] 3.865557</code></pre>
<p>Compute the p-value</p>
<pre class="r"><code>pvalue &lt;- 2 * pnorm(- abs(tstatistic)) #pnorm gives the distribution function of Normal
pvalue</code></pre>
<pre><code>## [1] 0.0001108361</code></pre>
<p>we can see, graphically, that the t-statistic is approximately N(0,1) if n is large.</p>
<pre class="r"><code># prepare empty vector for t-statistics
tstatistics &lt;- numeric(10000)
# set sample size
n &lt;- 300
# simulate 10000 t-statistics
for (i in 1:10000) {
  
  s &lt;- sample(0:1, 
              size = n,  
              prob = c(0.9, 0.1),
              replace = T)
  
  tstatistics[i] &lt;- (mean(s)-0.1)/sqrt(var(s)/n)
  
}
# plot density and compare to N(0,1) density
plot(density(tstatistics),
     xlab = &quot;t-statistic&quot;,
     main = &quot;Estimated Distribution of the t-statistic when n=300&quot;,
     lwd = 2,
     xlim = c(-4, 4),
     col = &quot;steelblue&quot;)

# N(0,1) density (dashed)
curve(dnorm(x), 
      add = T, 
      lty = 2, 
      lwd = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="confidence-interval" class="section level2">
<h2>Confidence interval</h2>
<pre class="r"><code># set seed
set.seed(1)

# generate some sample data
sampledata &lt;- rnorm(100, 10, 10) #Sample from a N(10,10)

mean(sampledata)</code></pre>
<pre><code>## [1] 11.08887</code></pre>
<pre class="r"><code>t.test(sampledata)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  sampledata
## t = 12.346, df = 99, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##   9.306651 12.871096
## sample estimates:
## mean of x 
##  11.08887</code></pre>
<pre class="r"><code>ls(t.test(sampledata)) #Outcomes of t.test</code></pre>
<pre><code>##  [1] &quot;alternative&quot; &quot;conf.int&quot;    &quot;data.name&quot;   &quot;estimate&quot;    &quot;method&quot;     
##  [6] &quot;null.value&quot;  &quot;p.value&quot;     &quot;parameter&quot;   &quot;statistic&quot;   &quot;stderr&quot;</code></pre>
<pre class="r"><code>t.test(sampledata)$&quot;conf.int&quot; #Just the desired result. 95% confidence interval</code></pre>
<pre><code>## [1]  9.306651 12.871096
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
<pre class="r"><code>t.test(sampledata, conf.level = 0.99) #Covers the true value with a probability of 99%</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  sampledata
## t = 12.346, df = 99, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 99 percent confidence interval:
##   8.729838 13.447909
## sample estimates:
## mean of x 
##  11.08887</code></pre>
</div>
<div id="means-comparison" class="section level2">
<h2>Means comparison</h2>
<p>To compare means from two different populations, we can also perform a t-test</p>
<pre class="r"><code># draw data from two different populations with equal mean
sample_pop1 &lt;- rnorm(100, 10, 10) #N(10,10)
sample_pop2 &lt;- rnorm(100, 10, 20) #N(10,20)

mean(sample_pop1)</code></pre>
<pre><code>## [1] 9.621919</code></pre>
<pre class="r"><code>mean(sample_pop2)</code></pre>
<pre><code>## [1] 10.59347</code></pre>
<pre class="r"><code># perform a two sample t-test
t.test(sample_pop1, sample_pop2) #Null hypothesis: the difference is zero</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  sample_pop1 and sample_pop2
## t = -0.4262, df = 139.59, p-value = 0.6706
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -5.478461  3.535358
## sample estimates:
## mean of x mean of y 
##  9.621919 10.593471</code></pre>
</div>
<div id="exercise" class="section level2">
<h2>Exercise</h2>
<ol style="list-style-type: decimal">
<li>Draw a sample of size=100 from a Standard Normal Distribution</li>
<li>Perform a t-test “by hands” (without the R function)</li>
<li>Perform the t-test using the function from R and compare the values</li>
<li>Interpret the result of the t-test</li>
<li>Repeat step <strong>1.</strong> 1000 times, storing the mean on a vector and plot the histogram</li>
</ol>
</div>
